---
layout: post
title: GVRNN
subtitle: Graph Variational Recurrent Neural Networks
---

ì´ê²ƒì€ 2022 MLSA Workshopì— ì œì¶œí•œ "Evaluation of creating scoring opportunities for teammates in soccer via trajectory prediction"ë…¼ë¬¸ì„ ë°”íƒ•ìœ¼ë¡œ ì œê°€ ê³µë¶€í•œ GVRNNì— ëŒ€í•œ ì„¤ëª…ì…ë‹ˆë‹¤.

- ìœ„ ë…¼ë¬¸ì€ GVRNNì„ í™œìš©í•˜ì—¬ ì„ ìˆ˜ë“¤ì˜ trajectoryë¥¼ ì˜ˆì¸¡í•˜ëŠ” ë¬¸ì œë¥¼ ë‹¤ë£¨ê³  ìˆìŠµë‹ˆë‹¤. ë…¼ë¬¸ì— ëŒ€í•´ì„œëŠ” ë³¸ blogì—ì„œ ì„¤ëª…í•˜ì§€ ì•Šê³  GVRNNì— ëŒ€í•´ì„œë§Œ ì„¤ëª…í•©ë‹ˆë‹¤. 
- GVRNNì„ ì„¤ëª…í•˜ë ¤ë©´, ê²°êµ­ AE(AutoEncoder), VAE(Variational AutoEncoder), VRNN(Variational Recurrent Neural Network), GNN(Graph Neural Network)ë¥¼ ëª¨ë‘ ì•Œì•„ì•¼í•œë‹¤. GVRNNì€ VRNNê³¼ GNNë¥¼ í™œìš©í•œ ê¸°ë²•ì´ë¯€ë¡œ 4ê°€ì§€ íŠ¹ì§•ì„ ëª¨ë‘ ì•ˆë‹¤ë©´, GVRNNë¥¼ ì´í•´í•  ìˆ˜ ìˆì„ ê²ƒì´ë‹¤.
- 4ê°€ì§€ ê°œë…ì„ í•˜ë‚˜ì˜ blogì— ë‹´ìœ¼ë ¤ë©´ ìš”ì•½ëœ ì •ë³´ë§Œì„ ì„¤ëª…í•  ìˆ˜ ë°–ì— ì—†ë‹¤. ë‚˜ì¤‘ì— ì¡°ê¸ˆ ë” ìì„¸íˆ ì“¸ ê³„íšì´ë‹¤.

### AE(AutoEncoder)
- ì˜¤í† ì¸ì½”ë”(AE)ëŠ” ì…ë ¥ ë°ì´í„°ë¥¼ ì••ì¶•í•œ í›„ ë³µì›í•˜ì—¬ representation learning(ë°ì´í„°ì˜ í‘œí˜„ì„ í•™ìŠµ)í•˜ëŠ” ë¹„ì§€ë„ í•™ìŠµ ì•Œê³ ë¦¬ì¦˜ì´ë‹¤.
  
      1. Encoder : ì…ë ¥ ë°ì´í„°ë¥¼ ë‚´ë¶€ í‘œí˜„(ì ì¬ ê³µê°„)ìœ¼ë¡œ ë³€í™˜ -> ì¶”ì¶œëœ íŠ¹ì§•ì„ Latent Vectorë¼ê³  ë¶€ë¦„
  
      2. Decoder : Encoderë¥¼ ê±°ì¹œ Latent Spaceë¥¼ ë°›ì•„ ì›ë³¸ ë°ì´í„°ê³¼ ê°™ì€ í˜•íƒœë¡œ ì¬êµ¬ì„±
  
- Model code github : [Model](https://github.com/dariocazzani/pytorch-AE/blob/master/models/AE.py)
  
![Model](https://blog.kakaocdn.net/dn/8JonH/btqFBec9cAF/mhxdDF930R0CrHs9NdUKv1/img.png)
  
### VAE(Variational AutoEncoder)
- ë³€ì´í˜• ì˜¤í† ì¸ì½”ë”(VAE)ëŠ” AEê³¼ ë¹„ìŠ·í•œ êµ¬ì¡°ë¥¼ ê°€ì§€ì§€ë§Œ, í™•ë¥  ë¶„í¬ë¥¼ ëª¨ë¸ë§í•œë‹¤ëŠ” ì ì—ì„œ ì°¨ì´ê°€ ìˆë‹¤

      1. Encoder : ì…ë ¥ ë°ì´í„°ë¥¼ ë‚´ë¶€ í‘œí˜„(ì ì¬ ê³µê°„)ìœ¼ë¡œ ë³€í™˜ -> í™•ë¥  ë¶„í¬ë¥¼ ì •ì˜í•˜ëŠ” í‰ê· ê³¼ í‘œì¤€í¸ì°¨ ì¶œë ¥
  
      2. Latent Space : AEê³¼ ë‹¤ë¥´ê²Œ VAEì—ì„œëŠ” Latent Spaceì—ì„œ noiseë¥¼ ì¶”ê°€í•¨(ë™ì¼í•œ ë°ì´í„° ìƒì„± ë°©ì§€) -> ì •ê·œë¶„í¬ë¡œ ë¶€í„° í•˜ë‚˜ì˜ noiseë¥¼ ìƒ˜í”Œë§í•œ í›„ ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ Latent vector zë¥¼ ì–»ëŠ”ë°, ì´ë¥¼ reparameterizeì´ë¼ í•œë‹¤.
  
      3. Decoder : Latend Spaceë¥¼ ê±°ì¹œ zë¥¼ ë°›ì•„ ì›ë³¸ ë°ì´í„°ê³¼ ê°™ì€ í˜•íƒœë¡œ ì¬êµ¬ì„±
  
- Model code github : [Model](https://github.com/dariocazzani/pytorch-AE/blob/master/models/VAE.py)
  
![Model](https://blog.kakaocdn.net/dn/b30Uzl/btrxY4wKngj/SucVwitDrRtQvi1xTHdrR0/img.png)

### VRNN
* RNNì˜ ì‹œê°„ì  ë™ì  íŠ¹ì„±ê³¼ VAEì˜ í™•ë¥ ì  ìƒì„± ëª¨ë¸ë§ë¥¼ ê²°í•©í–ˆë‹¤. ì‹œê°„ì— ë”°ë¼ ë³€í™”í•˜ëŠ” Trajectoryë¥¼ íš¨ê³¼ì ìœ¼ë¡œ í•™ìŠµí•˜ê¸° ìœ„í•´ì„œ RNNë„ì…

$$
\phi_{\theta}(z_t | x_{<t}, z_{<t}) = \phi_{\text{prior}}(h_{t-1})
$$

      1. Prior : ë°ì´í„°ë¥¼ ì ‘ê·¼í•˜ê¸° ì „ ê°€ì§€ê³  ìˆëŠ” ì‚¬ì „ ë¶„í¬ë¥¼ í†µí•´ì„œ ë°ì´í„°ë¥¼ ì¶”ì •í•¨. Encoderê°€ ì…ë ¥ë°ì´í„°ë¥¼ ë°›ì•„ Latent Spaceí‘œí˜„ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ì—­í• ì„ í•œë‹¤ë©´, Priorì€ Latent Spaceì— ëŒ€í•œ ì „ì²´ì ì¸ êµ¬ì¡°ì™€ ë¶„í¬ë¥¼ ì •ì˜í•¨ìœ¼ë¡œì¨ ë°ì´í„°ë¥¼ ìƒì„±í•  ë•Œ ì¼ë°˜í™”ëŠ¥ë ¥ì„ í–¥ìƒì‹œí‚¬ ìˆ˜ ìˆë‹¤. ìˆ˜ì‹ì€ tì‹œì  ì´ì „(ê³¼ê±°)ì˜ ì •ë³´ë§Œì„ í™œìš©í•œ ë¶„í¬ë¥¼ ì¶”ì •í•˜ëŠ” ì‹ì„ì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤.

    $$
    \ğ‘_ğœƒ (ğ‘§_ğ‘¡â”‚ğ‘¥_{<ğ‘¡}, ğ‘§_{<ğ‘¡} )= ğœ‘_{ğ‘ğ‘Ÿğ‘–ğ‘œğ‘Ÿ}(â„_{ğ‘¡âˆ’1})
    $$
  
      2. Latent Space : VAEê³¼ ê°™ì€ ì—­í• ì´ë‹¤. í•™ìŠµí•  ë•ŒëŠ” Encoderì˜ í™•ë¥  ë¶„í¬ë¥¼ ë°›ê³ , ë°ì´í„° ìƒì„±í•  ë•ŒëŠ” Priorì˜ í™•ë¥ ë¶„í¬ë¥¼ ë°›ëŠ”ë‹¤.
  
      3. Encoder(Inference) : ì…ë ¥ ë°ì´í„°ë¥¼ ë‚´ë¶€ í‘œí˜„(ì ì¬ ê³µê°„)ìœ¼ë¡œ ë³€í™˜ -> í•™ìŠµí•  ë•Œ ì‚¬ìš©
      
  $ğ‘_ğœƒ (ğ‘§_ğ‘¡â”‚ğ‘¥_{â‰¤ğ‘¡}  ğ‘§_{<ğ‘¡} )= ğœ‘_{ğ‘’ğ‘›ğ‘} (ğ‘¥_ğ‘¡, â„_{ğ‘¡âˆ’1})$

      4. Decoder(Generation) : Latend Spaceë¥¼ ê±°ì¹œ zë¥¼ ë°›ì•„ ì›ë³¸ ë°ì´í„°ê³¼ ê°™ì€ í˜•íƒœë¡œ ì¬êµ¬ì„±
      
  $ ğ‘_ğœƒ (ğ‘§_ğ‘¡â”‚ğ‘§_{â‰¤ğ‘¡}, ğ‘¥_{<ğ‘¡})= ğœ‘_{ğ‘‘ğ‘’ğ‘} (ğ‘§_ğ‘¡, â„_{ğ‘¡âˆ’1})$

      5. Recurrence : ì´ì „ ì‹œì ì˜ hidden stateê³¼ ì…ë ¥ë°ì´í„°, Latent Vecorë¥¼ í™œìš©í•˜ì—¬ í˜„ì¬ ì‹œì ì˜ hidden stateë¥¼ ì—…ë°ì´í„°í•˜ëŠ” ê³¼ì •ì´ë‹¤
      
  $â„_ğ‘¡=ğ‘“(ğ‘¥_ğ‘¡, ğ‘§_ğ‘¡, â„_{ğ‘¡âˆ’1})$

- Loss : VAEì˜ ì†ì‹¤ í•¨ìˆ˜ëŠ” ì£¼ë¡œ ë‘ ë¶€ë¶„ìœ¼ë¡œ êµ¬ì„±ë©ë‹ˆë‹¤: ì¬êµ¬ì„± ì†ì‹¤(reconstruction loss)ê³¼ ì •ê·œí™” ì†ì‹¤(Kullback-Leibler divergence). ì´ ë‘ ìš”ì†Œë¥¼ í•©ì³ Evidence Lower Bound (ELBO)ë¼ê³  í•˜ë©°, VAEì˜ ëª©í‘œëŠ” ELBOë¥¼ ìµœëŒ€í™”í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.
  
      1. Reconstruction Loss
            - ì…ë ¥ ë°ì´í„°ì™€ ì¶œë ¥ ë°ì´í„° ê°„ì˜ ì°¨ì´ë¥¼ ì¤„ì…ë‹ˆë‹¤. ëª¨ë¸ì´ ë°ì´í„°ë¥¼ ì–¼ë§ˆë‚˜ ì˜ ì¬êµ¬ì„±í•˜ëŠ”ì§€ ì¸¡ì •í•˜ëŠ” ì§€í‘œ
  
      2. Regularization Loss
            - ëª¨ë¸ì´ ë‹¨ìˆœíˆ ë°ì´í„°ë¥¼ ì¬ìƒì‚°í•˜ëŠ” ê²ƒì„ ë„˜ì–´ì„œ, ì¼ë°˜ì ì¸ ë°ì´í„° íŒ¨í„´ì„ ì´í•´í•˜ê³  ìƒˆë¡œìš´ ë°ì´í„°ë¥¼ ìƒì„±í•  ìˆ˜ ìˆê²Œ í•˜ëŠ” ì •ê·œí™” ì—­í• (ì…ë ¥ ë°ì´í„°ì˜ ë³µì‚¬ë³¸ ìƒì„± ë°©ì§€)
            - KL divergenceëŠ” Trajectoryê´€ì ì—ì„œ ë‹¤ìŒ ìœ„ì¹˜ë¥¼ ì˜ˆì¸¡í•  ë•Œ, ì´ì „ ìœ„ì¹˜ì™€ ë™ì¼í•œ ìœ„ì¹˜ë¥¼ ìƒì„±í•˜ì§€ ì•Šë„ë¡ í•˜ê¸° ìœ„í•œ ê²ƒê³¼ ìœ ì‚¬í•©ë‹ˆë‹¤. ì¦‰, ëª¨ë¸ì´ ë°ì´í„°ì˜ ë‹¤ì–‘ì„±ì„ ìœ ì§€í•˜ê³  ì˜ˆì¸¡ ê°€ëŠ¥í•œ íŒ¨í„´ì„ í•™ìŠµí•˜ë„ë¡ ìœ ë„í•©ë‹ˆë‹¤.

- Model code link : [Model](https://github.com/emited/VariationalRecurrentNeuralNetwork/blob/master/model.py)
  
![image](https://github.com/GunHeeJoe/GunHeeJoe.github.io/assets/112679136/19c89399-9ba1-463e-8867-ea61078dec90)


  

### GVRNN
- GVRNNì€ VRNNì— GNNê¸°ë²•ì„ ì¶”ê°€í•œ ê²ƒì´ë‹¤. ì¶•êµ¬ì˜ ê²½ìš° ê° ì„ ìˆ˜ë“¤ì˜ TrajectoryëŠ” ë‹¤ë¥¸ ì„ ìˆ˜ë“¤ì˜ ì˜í–¥ì„ ë°›ê¸° ë•Œë¬¸ì— GNNê¸°ë²•ë„ ì¶”ê°€í•œ ê²ƒì´ë‹¤. -> ë‹¤ì¤‘ ì—ì´ì „íŠ¸ì˜ ìƒí˜¸ì‘ìš©ì„ í•™ìŠµ
- Prior, Encoder(Inference), Decoder(Generation)ë¥¼ í†µí•´ ë‚˜ì˜¨ í™•ë¥ ë¶„í¬ì— GNNë¥¼ ì¶”ê°€í•˜ë¯€ë¡œì¨ ì„ ìˆ˜ë“¤ì˜ ìƒí˜¸ì‘ìš©ë„ í•™ìŠµí•˜ëŠ” êµ¬ì¡°
- Model code link : [Model](https://github.com/keisuke198619/C-OBSO/blob/main/vrnn/models/gvrnn.py)
  
![Model](https://github.com/GunHeeJoe/GunHeeJoe.github.io/assets/112679136/605202a0-3cf4-422e-87f5-fa1f8932cfcb)


